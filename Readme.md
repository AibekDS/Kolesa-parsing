Обзор

Этот проект направлен на сбор данных о автомобилях из сайта Kolesa.kz и создание модели предсказания цен. Сбор данных осуществляется с помощью веб-скрапинга и сохраняется в CSV файл. Эти данные затем будут использоваться для обучения и валидации модели машинного обучения для предсказания цен.

Особенности

    Веб-скрапинг: Извлекает информацию о автомобилях, такую как марка, модель, год выпуска, цена, город, тип кузова, характеристики двигателя, тип топлива, пробег, трансмиссия, тип привода и цвет.
    Хранение данных: Сохраняет извлеченные данные в CSV файл для дальнейшего анализа и обучения модели.
    Асинхронный парсинг: Использует асинхронное программирование для эффективного скрапинга данных с нескольких URL одновременно.

Требования

    Python 3.7+
    Модули: csv, asyncio, selenium, webdriver-manager, BeautifulSoup, fake_useragent, tqdm

Объяснение кода

    ● Функция парсинга данных
    
      Функция parse_data извлекает информацию о автомобиле из HTML-источника и записывает ее в CSV файл.

      def parse_data(src, car_number):
          # Логика парсинга
          # ...
    
    ● Асинхронные функции парсинга

      Функция parse_single открывает новую вкладку для каждого URL и парсит данные о автомобиле, в то время как функция parse_urls управляет задачами для нескольких URL.

      async def parse_single(driver, url):
          # Логика парсинга одного URL
          # ...
        
      async def parse_urls(driver, urls):
          tasks = [parse_single(driver, url) for url in urls]
          await asyncio.gather(*tasks)
    
    ● Основная функция

      Функция main инициализирует драйвер Chrome, переходит на веб-сайт и оркестрирует процесс парсинга.

      async def main():
          # Основная логика парсинга
          # ...
        
      await main()

Вклад

Будем рады вашему вкладу! Пожалуйста, форкните репозиторий и создайте pull request с вашими изменениями.

    

